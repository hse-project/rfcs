# Ensuring transaction kv-tuples are committed before ingesting into cN

## Problem

One of the invariants in cN is that newer kvsets contain newer data. Since cN
kvsets are searched in order from newest to oldest, this invariant allows cN
queries to terminate on the first kvset with a suitable match.

Recent changes in c0 allow transactions to store uncommitted kv-tuples in
"struct c0_kvmultiset" objects long enough to be considered for ingest into cN.
Uncommitted kv-tuples do not yet have sequence numbers. If they were ingested
into cN and later assigned a sequence number, the assigned number would be
higher than sequence numbers for other kv-tuples that have not yet been ingested
into cN. This would violate the invariant.

## Requirements

- Design must not prevent concurrent ingest operations

## Non-Requirements

- Design must not ingest uncommitted data

## Solution

### Overview

This RFC proposes a new data structure referred to as the **_Late Commit_**
structure, or simply **_LC_**. There will be one LC per KVDB.

During ingest, active txn kv-tuples will be stored in LC instead of being
ingested into cN. As transactions are aborted and committed, kv-tuples in LC
will become aborted and committed.

The ingest operation will scan LC to copy committed kv-tuples into cN. Ingested
LC kv-tuples must eventually be garbage collected along with aborted LC
kv-tuples.

Txn reads will search LC for uncommitted kv-tuples belonging to the txn as well
as for committed kv-tuples produced by other txns. Non-txn reads will search LC
for committed kv-tuples. Both txn and non-txn reads will provide a view seqno
when searching LC.

### Terminology

- **_kv-tuple_** -- A key and an associated value, tombstone or prefix
  tombstone. Note that (prefix) delete operations are mutations that add
  kv-tuples with (prefix) tombstones to the KVDB rather than actually removing a
  kv-tuple.
- **_c0kvms (struct c0_kvmultiset)_** -- A collection of kv-tuples in c0. Each
  KVDB has one **\_active c0kvms\_\_** and zero or more **_frozen c0kvms_**'s.
  The active c0kvms stores incoming kv-tuples (from HSE puts, deletes, etc.).
  When the active c0kvms becomes "full", it is frozen and a new active c0kvms is
  created.
- **_ingest_** refers the process of migrating kv-tuples from the oldest c0kvms
  into cN, at which point it becomes the newest cN kvset.
- **_dgen_** - A data generation number assigned to each c0kvms. The initial
  active c0kvms is assigned a dgen of 1. Each new active c0kvms is assigned a
  dgen one greater than the dgen of the previous active c0kvms. Dgen numbers
  persist across KVDB open/close so they are never reused for the life of a
  KVDB. Dgen numbers follow data into cN. cN kvsets created during ingest are
  associated with a single dgen (the same dgen as the ingested c0kvms). cN
  kvsets created during compaction of M kvsets with dgen numbers _x_ to
  _x\+M\-1_ are associated with that range of dgen numbers.
- A **_txn kv-tuple_** is a a key-value pair created by a transaction. A txn
  kv-tuple can be active, committed or aborted (i.e., in the same state as the
  transaction that created it).

Each c0kvms has a dgen number assigned when the c0kvms is made active. Dgen
numbers are unique across the life of a KVDB and can be used to identify a
particular c0kvms instance.

- **_c0kvms[d]_** : identifies the c0kvms with dgen _d_
- **_c0kvms[d].txn_seqno_frozen_** : the commit seqno of a txn that was
  committed before c0kvms[d] was frozen.
- **_c0kvms[d].txn_seqno_min_** : alias for _c0kvms[d-1].txn_seqno_frozen_, or
  _0_ if _d==1_.

For each kv-tuple _kv_, define:

- **_is_txn(kv)_** : true if and only if _kv_ originated in a transaction

For kv-tuples _kv_ such that _is_txn(kv) == true_:

- **_kv.txn_** : the transaction that originated _kv_
- **_kv.c0snr_** : the c0snr entry associated with _kv.txn_
- **_kv.c0snr.dgen_** : the max dgen of all c0kvms's containing kv-tuples
  associated with _kv.c0snr_
- **_kv.ingested_** : true if _kv_ is in LC and has already been ingested

The following definitions are defined so they apply in a logical way to non-txn
and txn kv-tuples:

- **_is_active(kv)_** : _is_txn(kv)_ and _kv.txn_ is active
- **_is_aborted(kv)_** : _is_txn(kv)_ and _kv.txn_ has been aborted
- **_is_committed(kv)_** : _!is_txn(kv)_ or _kv.txn_ has been committed

All committed kv-tuples have a concrete sequence number. For txn kv-tuples, it
is assigned when the transaction commits. For non-txn kv-tuples, it is assigned
when the kv-tuple in inserted into the active c0kvms.

- **_kv.seqno_** : if _is_committed(kv)_, the concrete sequence number assigned
  to _kv_, else undefined

For all kv-tuples _kv_, define:

- **_overlap(kv1,kv2)_** : _kv1_ and _kv2_ have the same key, or one is a prefix
  tombstone that matches the other's key

Each KVDB has single LC object, where:

- **_LC.entries_**: a set of kv-tuple objects
- **_LC.view_seqno_min_**: a lower bound on the view seqno used by current and
  future LC queries, increases monotonically over time

### Seqno Ordering

In release 1.9, given two cN kvsets, every kv-tuple in the newer kvset has a
seqno greater than or equal to every kv-tuple in the older kvset. This RFC
relaxes this so the ordering only applies to keys that overlap. Informally, the
new ordering invariant is: given two kv-tuples in the same kvs, the kv-tuple in
the newer c0kvms/LC/cnkvset has a larger sequence number than the kv-tuple in
older c0kvms/LC/cnkvset.

More formally, given a kv-tuple _kv_, define **_container(kv)_** to be the
c0kvms or LC or cN kvset that contains _kv_. Define **_newer than_** as a total
order an all containers:

_c1_ is newer than _c2_ if an only if:

- _c1_ is a c0kvms and _c2_ is LC, or
- _c1_ is LC and _c2_ is a cN kvset, or
- _c1_ has a higher dgen number than _c2_.

The new seqno ordering invariant can now be stated as follows:

Given two kv-tuples _kv1_ and _kv2_, if:

- _kv1_ and _kv2_ are in the same KVS, and
- _overlap(kv1, kv2) == true_, and
- _!is_txn(kv1) || is_committed(kv1)_, and
- _!is_txn(kv2) || is_committed(kv2)_, and
- _container(kv1)_ is newer than _container(kv2)_,

Then:

- _kv1.seqno >= kv2.seqno_.

### Garbage Collection

An entry can be removed from LC when it no longer needed for LC queries. Let
_kv_ be an entry in LC. Then _kv_ can be removed from LC if and only if _kv_ has
been ingested into cN and _kv.seqno < LC.view_seqno_min_, or if _kv_ has been
aborted.

Garbage collection will be implemented as part of the ingest operation.

### Ingest

The ingest operation must take care not to break transaction atomicity. Prior to
the ingest pipeline work, atomicity was ensured because all kv-tuples for a
transaction were part of the same ingest operation and ingest operations
themselves are atomic. In the new design, ingest operations are still atomic,
but (1) the kv-tuples in the c0kvms being ingested can flip to the committed
state while the ingest operation is in progress, and (2) a transactionâ€™s
kv-tuples can be spread among multiple c0kvms objects.

The first issue is handled by ensuring all ingested transaction kv-tuples are
committed and have a seqno less or equal the seqno of any recently committed
transaction (see _c0kvms[d].txn_seqno_frozen_).

There are two ways to deal with the second issue depending on use of the WAL:

- _(USE_WAL==1)_ Rely on knowledge that the WAL has persisted the transaction's
  commit and all of its kv-tuples, or
- _(USE_WAL==0)_ Ensure all of a transaction's kv-tuples are in the input c0kvms
  and LC before ingesting any of the transaction's kv-tuples.

We use the second approach (_USE_WAL==0_) approach because it provides an easy
way to "assign" each transaction to an ingest operation, which is helpful for
supporting concurrent ingest operations. We can revisit this when the WAL is
available to more efficiently support large transactions.

Algorithm for ingesting c0kvms with dgen d:

```
ingest(d) {

  Inputs:
    c0kvsm[d];
    LC;

  Outputs:
    cnkvset[d]
    LC;

  Algorithm:

    assert(c0kvms[d].txn_seqno_frozen >= c0kvms[d].txn_seqno_min);
    Create instance cnkvset[d], initally empty;
    Let new_lc_entries be a list of kv-tuples, initally empty;
    Let merge(A, B) represent the union of kv-tuples in A and B sorted by key;

    For each kv in merge(c0kvms[d], LC) {

        kv_from_kvms = (kv came from c0kvms[d]) ? true : false;
        ingest = false;

        if (kv_from_kvms) {
            if (!is_txn(kv)) {
                ingest = true;
            } else if (is_aborted(kv)) {
                ; // Do nothing.
            } else if (is_active(kv)) {
                add kv to new_lc_entries;
            } else {
                assert(is_committed(kv));
                assert(kv.seqno > c0kvms[d].txn_seqno_min);
                if (kv.seqno <= c0kvms[d].txn_seqno_frozen) {
                    // We have all kv-tuples for this txn, so it is safe to ingest.
                    ingest = true;
                } else {
                    // This will be handled by a future ingest.  Note this forces
                    // ingest operations to be serialized, but we have a fix to
                    // enable concurrent ingest.  We can split this for-loop into
                    // two parts: part 1 would be serialized and would include
                    // modifications to LC, part 2 would be concurrent and would
                    // include creating the output cnkvset.
                    add kv to new_lc_entries;
                }
            }
        }
        else {
            assert(is_txn(kv));
            if (is_aborted(kv)) {
                kv.gc = true;
            } else if (is_active(kv)) {
                ; // do nothing
            } else {
                assert(is_committed(kv));
                beyond_horizon = kv.seqno < LC.view_seqno_min;
                if (kv.seqno <= c0kvms[d].txn_seqno_min) {
                    // An old txn, might have been left in LC due to seqno horizon.
                    // If it has been ingested and beyond horizon, mark it for GC.
                    // Note the beyond_horizon check could be done in the GC task
                    // instead of here.
                    if (kv.ingested && beyond_horizon && !kv.gc)
                        kv.gc = true;
                } else if (kv.seqno <= c0kvms[d].txn_seqno_frozen) {
                    // This txn has been "assigned" to this ingest operation.
                    // In addition, we have all kv-tuples for this txn, so it
                    // is safe to ingest.
                    ingest = true;
                    kv.ingested = true;
                    kv.gc = beyond_horizon;
                } else {
                    ; // Do nothing.  This txn will be handled by a future ingest.
                }
            }
        }

        if (ingest) {
            add kv to cnkvset[d];
        }
    }

    // After the output cnkvset has been published:

    get LC write lock;
    for each (kv in new_lc_entries)
        lc_add(LC, kv);
    release LC write lock;
}

                -----------------------------
                Ingest and Garbage Collection
                -----------------------------
```

### LC Data Structure and API

LC will be implemented as an RCU bonsai tree backed by dynamic memory allocation
instead of by a _cheap_.

LC API:

```
lc_create();
lc_destroy();

// Point queries
lc_get();
lc_pfx_probe();

// Cursor support
// - These APIs mimic cursor APIs for c0 and cN and should plug right
//   into the existing KVS cursor implementation.  LOL.
lc_cursor_create();
lc_cursor_destroy();
lc_cursor_read();
lc_cursor_restore();
lc_cursor_seek();
lc_cursor_update();
```

## Failure and Recovery Handling

- _lc_create()_ will be called during _hse_kvdb_open()_. If _lc_create()_ fails,
  then _hse_kvdb_open()_ will fail.
- The ingest operation can fail due to problems with memory allocation or media
  writes. In either case, the system must be shutdown. This design does not
  provide a way to back out of partially completed ingestg operation.

## Testing Guidance

A good test workload consists of long-lived transactions that insert kv-tuples
along with a moderate to high rate of non-txn put operations. The non-txn put
operations will force ingests, and the long-lived transactions will force use of
LC.
